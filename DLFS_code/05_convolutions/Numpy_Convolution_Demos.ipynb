{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution demos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we use the batch, multi-channel convolution operation implemented in Numpy (that you can find [here](../lincoln/lincoln/conv.py)) to train a small convolutional neural network to more than 90% accuracy on MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jackson/Downloads/python-ai-lesson/DLFS_code/lincoln\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# 获取当前工作目录\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# 获取上一级目录的路径\n",
    "parent_directory = os.path.dirname(current_directory)\n",
    "\n",
    "# 构建lincoln模块的绝对路径\n",
    "lincoln_path = os.path.join(parent_directory, \"lincoln\")\n",
    "\n",
    "# 将lincoln的路径添加到sys.path中\n",
    "if lincoln_path not in sys.path:\n",
    "    sys.path.append(lincoln_path)\n",
    "\n",
    "print(lincoln_path)\n",
    "\n",
    "# 试图导入lincoln模块\n",
    "import lincoln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import lincoln\n",
    "from lincoln.layers import Dense\n",
    "from lincoln.losses import SoftmaxCrossEntropy, MeanSquaredError\n",
    "from lincoln.optimizers import Optimizer, SGD, SGDMomentum\n",
    "from lincoln.activations import Sigmoid, Tanh, Linear, ReLU\n",
    "from lincoln.network import NeuralNetwork\n",
    "from lincoln.train import Trainer\n",
    "from lincoln.utils import mnist\n",
    "from lincoln.layers import Conv2D\n",
    "\n",
    "X_train, y_train, X_test, y_test = mnist.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = X_train - np.mean(X_train), X_test - np.mean(X_train)\n",
    "X_train, X_test = X_train / np.std(X_train), X_test / np.std(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_conv, X_test_conv = X_train.reshape(-1, 1, 28, 28), X_test.reshape(-1, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = len(y_train)\n",
    "train_labels = np.zeros((num_labels, 10))\n",
    "for i in range(num_labels):\n",
    "    train_labels[i][y_train[i]] = 1\n",
    "\n",
    "num_labels = len(y_test)\n",
    "test_labels = np.zeros((num_labels, 10))\n",
    "for i in range(num_labels):\n",
    "    test_labels[i][y_test[i]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy_model(model, test_set):\n",
    "    return print(f'''The model validation accuracy is: \n",
    "    {np.equal(np.argmax(model.forward(test_set, inference=True), axis=1), y_test).sum() * 100.0 / test_set.shape[0]:.2f}%''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 1, 28, 28)\n",
      "batch 0 loss 29.39081420179624\n",
      "batch 10 loss 14.246209255162467\n",
      "batch 20 loss 5.145601082792306\n",
      "batch 30 loss 5.458890351306932\n",
      "batch 40 loss 6.212484691146775\n",
      "batch 50 loss 7.330635019816992\n",
      "batch 60 loss 7.114922248515322\n",
      "batch 70 loss 7.504527488877328\n",
      "batch 80 loss 9.269616581904634\n",
      "batch 90 loss 4.057991645613421\n",
      "batch 100 loss 7.484871668024179\n",
      "Validation accuracy after 100 batches is 86.16%\n",
      "batch 110 loss 9.032577973610577\n",
      "batch 120 loss 7.785439174702796\n",
      "batch 130 loss 4.83542870835372\n",
      "batch 140 loss 4.449906693125154\n",
      "batch 150 loss 6.286766773306007\n",
      "batch 160 loss 3.70839924835497\n",
      "batch 170 loss 4.1511313455886105\n",
      "batch 180 loss 4.051256319547694\n",
      "batch 190 loss 4.144680090546839\n",
      "batch 200 loss 4.106304692568035\n",
      "Validation accuracy after 200 batches is 88.73%\n",
      "batch 210 loss 7.663036954872628\n",
      "batch 220 loss 4.835428708353721\n",
      "batch 230 loss 8.088886208172125\n",
      "batch 240 loss 3.0658714918130014\n",
      "batch 250 loss 3.4460173752255145\n",
      "batch 260 loss 6.218058305628511\n",
      "batch 270 loss 7.598530821698703\n",
      "batch 280 loss 6.634617355080749\n",
      "batch 290 loss 4.437587975236069\n",
      "batch 300 loss 3.1003940198162643\n",
      "Validation accuracy after 300 batches is 87.02%\n",
      "batch 310 loss 5.747043967301635\n",
      "batch 320 loss 3.4294146513199073\n",
      "batch 330 loss 3.4561600605355483\n",
      "batch 340 loss 2.0723265950087373\n",
      "batch 350 loss 4.985934293112492\n",
      "batch 360 loss 5.599631152222284\n",
      "batch 370 loss 5.544470626172134\n",
      "batch 380 loss 5.201001252726767\n",
      "batch 390 loss 3.430333776716327\n",
      "batch 400 loss 3.4542196127873352\n",
      "Validation accuracy after 400 batches is 91.16%\n",
      "batch 410 loss 3.9490087659491375\n",
      "batch 420 loss 7.4468084207403065\n",
      "batch 430 loss 2.0723265958934634\n",
      "batch 440 loss 4.144655713637241\n",
      "batch 450 loss 5.553640771794362\n",
      "batch 460 loss 3.548372443269852\n",
      "batch 470 loss 3.464560444171755\n",
      "batch 480 loss 4.18092179784996\n",
      "batch 490 loss 3.584959067354125\n",
      "batch 500 loss 3.4546667857500704\n",
      "Validation accuracy after 500 batches is 90.74%\n",
      "batch 510 loss 3.1199213025558845\n",
      "batch 520 loss 4.144653192888744\n",
      "batch 530 loss 1.3815510666724917\n",
      "batch 540 loss 4.146008499026832\n",
      "batch 550 loss 4.1446531800174755\n",
      "batch 560 loss 2.7631021301266485\n",
      "batch 570 loss 3.4543295644094427\n",
      "batch 580 loss 2.767749290372499\n",
      "batch 590 loss 3.514193560422633\n",
      "batch 600 loss 2.0120276838586393\n",
      "Validation accuracy after 600 batches is 91.80%\n",
      "batch 610 loss 6.7979538204100125\n",
      "batch 620 loss 3.3079196823236456\n",
      "batch 630 loss 4.84777944235935\n",
      "batch 640 loss 4.19322255182388\n",
      "batch 650 loss 2.0691278203368193\n",
      "batch 660 loss 4.568706666367206\n",
      "batch 670 loss 2.1802776691790533\n",
      "batch 680 loss 3.885855929700146\n",
      "batch 690 loss 2.998437073209339\n",
      "batch 700 loss 0.6907755383362456\n",
      "Validation accuracy after 700 batches is 89.59%\n",
      "batch 710 loss 1.7187760784432575\n",
      "batch 720 loss 2.0723370886911883\n",
      "batch 730 loss 4.835428708353721\n",
      "batch 740 loss 2.8610504122145404\n",
      "batch 750 loss 2.2140243454798427\n",
      "batch 760 loss 1.3815510684145191\n",
      "batch 770 loss 4.144653180017475\n",
      "batch 780 loss 2.7631021233449835\n",
      "batch 790 loss 4.555023479084787\n",
      "batch 800 loss 1.3815510666724917\n",
      "Validation accuracy after 800 batches is 92.03%\n",
      "batch 810 loss 4.363786724520583\n",
      "batch 820 loss 1.3856763896354949\n",
      "batch 830 loss 5.81713155906877\n",
      "batch 840 loss 5.526204236689966\n",
      "batch 850 loss 4.1446531800174755\n",
      "batch 860 loss 2.321115299757378\n",
      "batch 870 loss 2.7635552688872\n",
      "batch 880 loss 2.0723265950845677\n",
      "batch 890 loss 2.0723265950087377\n",
      "batch 900 loss 5.959388579604883\n",
      "Validation accuracy after 900 batches is 85.50%\n",
      "batch 910 loss 5.221245281458133\n",
      "batch 920 loss 2.763102123344983\n",
      "batch 930 loss 1.3289128378975577\n",
      "batch 940 loss 3.789745627083316\n",
      "batch 950 loss 3.6206299905507064\n",
      "batch 960 loss 3.453890230538399\n",
      "batch 970 loss 2.0723265950087377\n",
      "batch 980 loss 5.527202691919853\n",
      "batch 990 loss 3.4955021881868134\n",
      "Validation loss after 1 epochs is 3.785\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(\n",
    "    layers=[Conv2D(out_channels=16,\n",
    "                   param_size=5,\n",
    "                   dropout=0.8,\n",
    "                   weight_init=\"glorot\",\n",
    "                   flatten=True,\n",
    "                  activation=Tanh()),\n",
    "            Dense(neurons=10, \n",
    "                  activation=Linear())],\n",
    "            loss = SoftmaxCrossEntropy(), \n",
    "seed=20190402)\n",
    "\n",
    "trainer = Trainer(model, SGDMomentum(lr = 0.1, momentum=0.9))\n",
    "print(X_train_conv.shape)\n",
    "trainer.fit(X_train_conv, train_labels, X_test_conv, test_labels,\n",
    "            epochs = 1,\n",
    "            eval_every = 1,\n",
    "            seed=20190402,\n",
    "            batch_size=60,\n",
    "            conv_testing=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model validation accuracy is: \n",
      "    90.08%\n"
     ]
    }
   ],
   "source": [
    "calc_accuracy_model(model, X_test_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 1, 28, 28)\n",
      "(1156, 60, 1, 5, 5)\n",
      "transposed_mm shape: (60, 784, 16, 5, 5)\n",
      "param_reshaped shape: (400, 1)\n",
      "(1156, 60, 1, 5, 5)\n",
      "batch 0 loss 28.011792087524245\n",
      "(1156, 60, 1, 5, 5)\n",
      "transposed_mm shape: (60, 784, 16, 5, 5)\n",
      "param_reshaped shape: (400, 1)\n",
      "(1156, 60, 1, 5, 5)\n",
      "transposed_mm shape: (60, 784, 16, 5, 5)\n",
      "param_reshaped shape: (400, 1)\n",
      "(1156, 60, 1, 5, 5)\n",
      "transposed_mm shape: (60, 784, 16, 5, 5)\n",
      "param_reshaped shape: (400, 1)\n",
      "(1156, 60, 1, 5, 5)\n",
      "transposed_mm shape: (60, 784, 16, 5, 5)\n",
      "param_reshaped shape: (400, 1)\n",
      "(1156, 60, 1, 5, 5)\n",
      "transposed_mm shape: (60, 784, 16, 5, 5)\n",
      "param_reshaped shape: (400, 1)\n",
      "(1156, 60, 1, 5, 5)\n",
      "transposed_mm shape: (60, 784, 16, 5, 5)\n",
      "param_reshaped shape: (400, 1)\n",
      "(1156, 60, 1, 5, 5)\n",
      "transposed_mm shape: (60, 784, 16, 5, 5)\n",
      "param_reshaped shape: (400, 1)\n",
      "(1156, 60, 1, 5, 5)\n",
      "transposed_mm shape: (60, 784, 16, 5, 5)\n",
      "param_reshaped shape: (400, 1)\n",
      "(1156, 60, 1, 5, 5)\n",
      "transposed_mm shape: (60, 784, 16, 5, 5)\n",
      "param_reshaped shape: (400, 1)\n",
      "(1156, 60, 1, 5, 5)\n",
      "transposed_mm shape: (60, 784, 16, 5, 5)\n",
      "param_reshaped shape: (400, 1)\n",
      "(1156, 60, 1, 5, 5)\n",
      "batch 10 loss 8.023026082832722\n",
      "(1156, 60, 1, 5, 5)\n",
      "transposed_mm shape: (60, 784, 16, 5, 5)\n",
      "param_reshaped shape: (400, 1)\n",
      "(1156, 60, 1, 5, 5)\n",
      "transposed_mm shape: (60, 784, 16, 5, 5)\n",
      "param_reshaped shape: (400, 1)\n",
      "(1156, 60, 1, 5, 5)\n",
      "transposed_mm shape: (60, 784, 16, 5, 5)\n",
      "param_reshaped shape: (400, 1)\n",
      "(1156, 60, 1, 5, 5)\n",
      "transposed_mm shape: (60, 784, 16, 5, 5)\n",
      "param_reshaped shape: (400, 1)\n",
      "(1156, 60, 1, 5, 5)\n",
      "transposed_mm shape: (60, 784, 16, 5, 5)\n",
      "param_reshaped shape: (400, 1)\n",
      "(1156, 60, 1, 5, 5)\n",
      "transposed_mm shape: (60, 784, 16, 5, 5)\n",
      "param_reshaped shape: (400, 1)\n",
      "(1156, 60, 1, 5, 5)\n",
      "transposed_mm shape: (60, 784, 16, 5, 5)\n",
      "param_reshaped shape: (400, 1)\n",
      "(1156, 60, 1, 5, 5)\n",
      "transposed_mm shape: (60, 784, 16, 5, 5)\n",
      "param_reshaped shape: (400, 1)\n",
      "(1156, 60, 1, 5, 5)\n",
      "transposed_mm shape: (60, 784, 16, 5, 5)\n",
      "param_reshaped shape: (400, 1)\n",
      "(1156, 60, 1, 5, 5)\n",
      "transposed_mm shape: (60, 784, 16, 5, 5)\n",
      "param_reshaped shape: (400, 1)\n",
      "(1156, 60, 1, 5, 5)\n",
      "batch 20 loss 3.839523131553846\n",
      "(1156, 60, 1, 5, 5)\n",
      "transposed_mm shape: (60, 784, 16, 5, 5)\n",
      "param_reshaped shape: (400, 1)\n",
      "(1156, 60, 1, 5, 5)\n",
      "transposed_mm shape: (60, 784, 16, 5, 5)\n",
      "param_reshaped shape: (400, 1)\n",
      "(1156, 60, 1, 5, 5)\n",
      "transposed_mm shape: (60, 784, 16, 5, 5)\n",
      "param_reshaped shape: (400, 1)\n",
      "(1156, 60, 1, 5, 5)\n",
      "transposed_mm shape: (60, 784, 16, 5, 5)\n",
      "param_reshaped shape: (400, 1)\n",
      "(1156, 60, 1, 5, 5)\n",
      "transposed_mm shape: (60, 784, 16, 5, 5)\n",
      "param_reshaped shape: (400, 1)\n",
      "(1156, 60, 1, 5, 5)\n",
      "transposed_mm shape: (60, 784, 16, 5, 5)\n",
      "param_reshaped shape: (400, 1)\n",
      "(1156, 60, 1, 5, 5)\n",
      "transposed_mm shape: (60, 784, 16, 5, 5)\n",
      "param_reshaped shape: (400, 1)\n",
      "(1156, 60, 1, 5, 5)\n",
      "transposed_mm shape: (60, 784, 16, 5, 5)\n",
      "param_reshaped shape: (400, 1)\n",
      "(1156, 60, 1, 5, 5)\n",
      "transposed_mm shape: (60, 784, 16, 5, 5)\n",
      "param_reshaped shape: (400, 1)\n",
      "(1156, 60, 1, 5, 5)\n",
      "transposed_mm shape: (60, 784, 16, 5, 5)\n",
      "param_reshaped shape: (400, 1)\n",
      "(1156, 60, 1, 5, 5)\n",
      "batch 30 loss 6.102669981638197\n",
      "(1156, 60, 1, 5, 5)\n",
      "transposed_mm shape: (60, 784, 16, 5, 5)\n",
      "param_reshaped shape: (400, 1)\n",
      "(1156, 60, 1, 5, 5)\n",
      "transposed_mm shape: (60, 784, 16, 5, 5)\n",
      "param_reshaped shape: (400, 1)\n",
      "(1156, 60, 1, 5, 5)\n",
      "transposed_mm shape: (60, 784, 16, 5, 5)\n",
      "param_reshaped shape: (400, 1)\n",
      "(1156, 60, 1, 5, 5)\n",
      "transposed_mm shape: (60, 784, 16, 5, 5)\n",
      "param_reshaped shape: (400, 1)\n",
      "(1156, 60, 1, 5, 5)\n",
      "transposed_mm shape: (60, 784, 16, 5, 5)\n",
      "param_reshaped shape: (400, 1)\n",
      "(1156, 60, 1, 5, 5)\n",
      "transposed_mm shape: (60, 784, 16, 5, 5)\n",
      "param_reshaped shape: (400, 1)\n",
      "(1156, 60, 1, 5, 5)\n",
      "transposed_mm shape: (60, 784, 16, 5, 5)\n",
      "param_reshaped shape: (400, 1)\n",
      "(1156, 60, 1, 5, 5)\n",
      "transposed_mm shape: (60, 784, 16, 5, 5)\n",
      "param_reshaped shape: (400, 1)\n",
      "(1156, 60, 1, 5, 5)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[294], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m trainerkk \u001b[38;5;241m=\u001b[39m Trainer(model22, SGDMomentum(lr \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m, momentum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m))\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(X_train_conv\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 15\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_conv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test_conv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m            \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m            \u001b[49m\u001b[43meval_every\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m            \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20190402\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconv_testing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m;\n",
      "File \u001b[0;32m~/Downloads/python-ai-lesson/DLFS_code/lincoln/lincoln/train.py:59\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, X_train, y_train, X_test, y_test, epochs, eval_every, batch_size, seed, single_output, restart, early_stopping, conv_testing)\u001b[0m\n\u001b[1;32m     54\u001b[0m batch_generator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_batches(X_train, y_train,\n\u001b[1;32m     55\u001b[0m                                         batch_size)\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ii, (X_batch, y_batch) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(batch_generator):\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m conv_testing:\n",
      "File \u001b[0;32m~/Downloads/python-ai-lesson/DLFS_code/lincoln/lincoln/network.py:81\u001b[0m, in \u001b[0;36mNeuralNetwork.train_batch\u001b[0;34m(self, X_batch, y_batch, inference)\u001b[0m\n\u001b[1;32m     78\u001b[0m batch_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss\u001b[38;5;241m.\u001b[39mforward(prediction, y_batch)\n\u001b[1;32m     79\u001b[0m loss_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 81\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss_grad\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m batch_loss\n",
      "File \u001b[0;32m~/Downloads/python-ai-lesson/DLFS_code/lincoln/lincoln/network.py:28\u001b[0m, in \u001b[0;36mLayerBlock.backward\u001b[0;34m(self, loss_grad)\u001b[0m\n\u001b[1;32m     26\u001b[0m grad \u001b[38;5;241m=\u001b[39m loss_grad\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers):\n\u001b[0;32m---> 28\u001b[0m     grad \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m grad\n",
      "File \u001b[0;32m~/Downloads/python-ai-lesson/DLFS_code/lincoln/lincoln/layers.py:50\u001b[0m, in \u001b[0;36mLayer.backward\u001b[0;34m(self, output_grad)\u001b[0m\n\u001b[1;32m     47\u001b[0m assert_same_shape(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput, output_grad)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m operation \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moperations[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m---> 50\u001b[0m     output_grad \u001b[38;5;241m=\u001b[39m \u001b[43moperation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_grad\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m input_grad \u001b[38;5;241m=\u001b[39m output_grad\n\u001b[1;32m     54\u001b[0m assert_same_shape(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_, input_grad)\n",
      "File \u001b[0;32m~/Downloads/python-ai-lesson/DLFS_code/lincoln/lincoln/base.py:48\u001b[0m, in \u001b[0;36mParamOperation.backward\u001b[0;34m(self, output_grad)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackward\u001b[39m(\u001b[38;5;28mself\u001b[39m, output_grad: ndarray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ndarray:\n\u001b[1;32m     46\u001b[0m     assert_same_shape(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput, output_grad)\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_grad\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_param_grad(output_grad)\n\u001b[1;32m     51\u001b[0m     assert_same_shape(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_grad)\n",
      "File \u001b[0;32m~/Downloads/python-ai-lesson/DLFS_code/lincoln/lincoln/conv.py:233\u001b[0m, in \u001b[0;36mConv2D_Op._input_grad\u001b[0;34m(self, output_grad)\u001b[0m\n\u001b[1;32m    230\u001b[0m img_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m3\u001b[39m]\n\u001b[1;32m    231\u001b[0m img_height \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m--> 233\u001b[0m mm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_output_patches\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_grad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;66;03m# print(\"mm:\",mm.shape)\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \n\u001b[1;32m    236\u001b[0m \u001b[38;5;66;03m# transposed_mm = mm.transpose(1, 0, 2, 3, 4)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    243\u001b[0m \n\u001b[1;32m    244\u001b[0m     \u001b[38;5;66;03m# 转置 mm 以使 batch_size 成为第一个维度\u001b[39;00m\n\u001b[1;32m    245\u001b[0m transposed_mm \u001b[38;5;241m=\u001b[39m mm\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m)\n",
      "File \u001b[0;32m~/Downloads/python-ai-lesson/DLFS_code/lincoln/lincoln/conv.py:87\u001b[0m, in \u001b[0;36mConv2D_Op._get_output_patches\u001b[0;34m(self, output_grad, patch_size)\u001b[0m\n\u001b[1;32m     82\u001b[0m         patches\u001b[38;5;241m.\u001b[39mappend(patch)\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# expected_patches = 28 * 28\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# print(f\"Expected number of patches: {expected_patches}, Actual number of patches: {len(patches)}\")\u001b[39;00m\n\u001b[0;32m---> 87\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatches\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/numpy/core/shape_base.py:456\u001b[0m, in \u001b[0;36mstack\u001b[0;34m(arrays, axis, out, dtype, casting)\u001b[0m\n\u001b[1;32m    454\u001b[0m sl \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m),) \u001b[38;5;241m*\u001b[39m axis \u001b[38;5;241m+\u001b[39m (_nx\u001b[38;5;241m.\u001b[39mnewaxis,)\n\u001b[1;32m    455\u001b[0m expanded_arrays \u001b[38;5;241m=\u001b[39m [arr[sl] \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpanded_arrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcasting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcasting\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model22 = NeuralNetwork(\n",
    "    layers=[Conv2D(out_channels=16,\n",
    "                   param_size=5,\n",
    "                   dropout=0.8,\n",
    "                   weight_init=\"glorot\",\n",
    "                   flatten=True,\n",
    "                  activation=Tanh()),\n",
    "            Dense(neurons=10, \n",
    "                  activation=Linear())],\n",
    "            loss = SoftmaxCrossEntropy(), \n",
    "seed=20190402)\n",
    "\n",
    "trainerkk = Trainer(model22, SGDMomentum(lr = 0.1, momentum=0.9))\n",
    "print(X_train_conv.shape)\n",
    "trainer.fit(X_train_conv, train_labels, X_test_conv, test_labels,\n",
    "            epochs = 1,\n",
    "            eval_every = 1,\n",
    "            seed=20190402,\n",
    "            batch_size=60,\n",
    "            conv_testing=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
